{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torch\n",
    "!pip install datasets\n",
    "!pip install wandb\n",
    "!pip install transformers==4.28.0\n",
    "! pip install -U git+https://github.com/huggingface/accelerate.git"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T15:06:22.057952Z",
     "iopub.execute_input": "2023-07-07T15:06:22.058691Z",
     "iopub.status.idle": "2023-07-07T15:07:57.295462Z",
     "shell.execute_reply.started": "2023-07-07T15:06:22.058647Z",
     "shell.execute_reply": "2023-07-07T15:07:57.294238Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%env \"WANDB_API_KEY\" \"ac00fe143a161e86bd1a8e56b299cc151e02fa1a\"\n",
    "%env \"WANDB_USERNAME\" \"water7arc\"\n",
    "import wandb\n",
    "wandb.login(key=\"ac00fe143a161e86bd1a8e56b299cc151e02fa1a\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T15:07:57.299493Z",
     "iopub.execute_input": "2023-07-07T15:07:57.299872Z",
     "iopub.status.idle": "2023-07-07T15:08:01.182211Z",
     "shell.execute_reply.started": "2023-07-07T15:07:57.299838Z",
     "shell.execute_reply": "2023-07-07T15:08:01.181116Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer, EarlyStoppingCallback"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T15:08:01.183854Z",
     "iopub.execute_input": "2023-07-07T15:08:01.184544Z",
     "iopub.status.idle": "2023-07-07T15:08:25.605345Z",
     "shell.execute_reply.started": "2023-07-07T15:08:01.184508Z",
     "shell.execute_reply": "2023-07-07T15:08:25.604305Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        context = self.data[index][\"context\"]\n",
    "        answer_start = self.data[index][\"answers\"][\"answer_start\"][0]\n",
    "        answer_end = answer_start + len(self.data[index][\"answers\"][\"text\"][0])\n",
    "        new_context = context[:answer_start] + \\\n",
    "                                      \"</s>\" + context[answer_start:answer_end] + \"</s>\" + context[answer_end:]\n",
    "\n",
    "        tokenized_in = self.tokenizer(\n",
    "            new_context,\n",
    "            text_target=self.data[index][\"question\"],\n",
    "            max_length=384,\n",
    "            truncation=\"only_first\",\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        tokenized_in[\"labels\"][tokenized_in[\"labels\"] == self.tokenizer.pad_token_id] = -100\n",
    "        return {\"input_ids\": tokenized_in[\"input_ids\"][0], \"labels\": tokenized_in[\"labels\"][0],\n",
    "                \"attention_mask\": tokenized_in[\"attention_mask\"][0]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T15:08:25.607588Z",
     "iopub.execute_input": "2023-07-07T15:08:25.608458Z",
     "iopub.status.idle": "2023-07-07T15:08:25.618097Z",
     "shell.execute_reply.started": "2023-07-07T15:08:25.608422Z",
     "shell.execute_reply": "2023-07-07T15:08:25.617166Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "squad = load_dataset(\"squad\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "tokenized_squad_train = MyDataset(squad[\"train\"], tokenizer)\n",
    "tokenized_squad_val = MyDataset(squad[\"validation\"], tokenizer)\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/t5-base-fine_tune/\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=50,\n",
    "    push_to_hub=False,\n",
    "    report_to=[\"wandb\"],\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end = True,\n",
    "    # no_cuda=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad_train,\n",
    "    eval_dataset=tokenized_squad_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T15:08:25.619866Z",
     "iopub.execute_input": "2023-07-07T15:08:25.620683Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
